{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum\n",
    "from time import sleep\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.sql.functions import to_timestamp, expr, col, concat_ws, slice, split\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "spark = SparkSession.builder.appName(\"github_commit_analysis\").getOrCreate()\n",
    "\n",
    "df = spark.read.parquet(\"/app/data/full.parquet\", inferSchema=True, header=True, multiLine=True)\n",
    "\n",
    "print(\"--- Load %s seconds ---\" % (time.time() - start_time))\n",
    "print(df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 1\n",
    "\n",
    "df_non_null = df.filter(df.repo.isNotNull())\n",
    "df_grouped = df_non_null.groupBy(\"repo\").agg(F.count(\"*\").alias(\"commit_count\")).orderBy(F.desc(\"commit_count\")).limit(10)\n",
    "df_grouped.show(truncate=False)\n",
    "\n",
    "print(\"--- 1- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 2\n",
    "df_spark = df_non_null.filter(df_non_null.repo == 'apache/spark')\n",
    "df_spark_grouped = df_spark.groupBy(\"author\").agg(F.count(\"*\").alias(\"commit_count\")).orderBy(F.desc(\"commit_count\"))\n",
    "df_spark_grouped_top = df_spark_grouped.limit(1)\n",
    "df_spark_grouped_top.show(truncate=False)\n",
    "\n",
    "print(\"--- 2- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 3\n",
    "date_format = \"MMM d HH:mm:ss yyyy Z\"\n",
    "\n",
    "df_spark_extract = df_spark.withColumn(\"date\", concat_ws(\" \", slice(split(df_spark[\"date\"], \" \"), 2, int(1e9))))\n",
    "print(\"---3 extract %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "df_convert = df_spark_extract.withColumn(\"date\", to_timestamp(col(\"date\"), date_format))\n",
    "print(\"---3 timestamp %s seconds ---\" % (time.time() - start_time))\n",
    "df_spark_four_year = df_convert.filter((df_convert.date >= expr(\"date_sub(current_date(), 4 * 365)\")))\n",
    "print(\"---3 filter by date %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "df_spark_four_year_grouped = df_spark_four_year.groupBy(\"author\").agg(F.count(\"*\").alias(\"commit_count\")).orderBy(F.desc(\"commit_count\"))\n",
    "print(\"---3 group by %s seconds ---\" % (time.time() - start_time))\n",
    " \n",
    "#print(df_time.printSchema())\n",
    "df_spark_four_year_grouped.show(truncate=False)\n",
    "\n",
    "print(\"---3 final %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 4\n",
    "\n",
    "stop_word_remover = StopWordsRemover()\n",
    "stop_word_remover.setInputCol(\"words_split\")\n",
    "stop_word_remover.setOutputCol(\"no_stop_words\")\n",
    "\n",
    "df_non_null_2 = df_non_null.filter(df_non_null.message.isNotNull())\n",
    "df_grouped = df_non_null_2.withColumn('words_split', F.split(df_non_null_2.message, \" \"))\n",
    "\n",
    "\n",
    "df_grouped = stop_word_remover.transform(df_grouped)\n",
    "df_grouped = df_grouped.withColumn('word', F.explode(df_grouped.no_stop_words))\n",
    "df_grouped = df_grouped.filter(df_grouped.word != '').filter(df_grouped.word != '\\n').filter(df_grouped.word != '*').filter(df_grouped.word != '-')\n",
    "df_grouped = df_grouped.groupBy(\"word\").agg(F.count(\"word\").alias(\"word_count\")).orderBy(F.desc(\"word_count\")).limit(10)\n",
    "df_grouped.show(truncate=False)\n",
    "\n",
    "print(\"---4 %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
